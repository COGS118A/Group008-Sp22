{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 118A- Project Checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Names\n",
    "\n",
    "- Caitlin Connolly\n",
    "- Carolyn Yatco\n",
    "- Abby Koornwinder\n",
    "- Joshua Widjanarko\n",
    "- Caike Campana"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstract \n",
    "Our project focuses on attempting to predict both a hotel's average score based on their reviews. We will be utilizing “515K Hotel Reviews Data in Europe” from Kaggle. This dataset contains 515,000 reviews from 1493 different hotels and contains the review which separated by the positive and negative portions, the number word count of the positive and negative portion respectively, locations of hotel, days since the review. In addition, we will be doing sentiment analysis within the positive and negative portions to get the degree of the positivity and negativity.After the sentiment analysis we will be testing different models(OLS, K-Nearest Neighbor, etc) and determining which model has the highest accuracy. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background\n",
    "Beyond location, price, and amenities, consumers judge their perception on a possible hotel to stay out based on the experience “or reviews” of previous guests. For example, according to TripAdvisor, a site for hotel and restaurant reviews and booking, roughly 81% of people always or frequently check a hotel’s reviews before booking <a name=\"lorenz\"></a>[<sup>[1]</sup>]. However, not all reviews and experiences are weighted equally. According to Sparks, B.A, and Browning, noticed that how information is framed within the review as well as the the focus of the review itself makes the biggest difference in how much a review would affect the overall view of a hotel  <a name=\"admonish\"></a>[<sup>[2]</sup>]. This begs the question on whether a computer can take a look at these reviews and determine the trust(in the form of ratings) that a hotel has in a similar way to how humans prioritze certain ideas, information, and looking at the overall sentiments.. Sentiment analysis, the ability of extracting emotion, feeling, and other subjective states, has been used on a wide arrangement of different reviews from movies on Netflix to restaurant reviews <a name=\"sotanote\"></a>[<sup>[3]</sup>]. However, most work on reviews ends with extracting the overall positivity or negativity of the review, not seeing if we can predict or gain insight on the overall view or rating of the hotel, movie, or other thing being reviewed. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement\n",
    "\n",
    "Our goal is to create a classifier for hotels in the European continent. We are going to use data from a review website its features, such as: Location; Negative and Positive reviews; user assigned tags; review age, and all the other features available. Thus, we combine the features into a classifier model and predict what will be the overall score of the hotel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "We are going to use the dataset [515K Hotel Reviews Data in Europe\n",
    "](https://www.kaggle.com/datasets/jiashenliu/515k-hotel-reviews-data-in-europe) from the repository Kaggle and generated by the user Jianshen Liu. \n",
    "\n",
    "The dataset contains 515000 reviews of 1493 hotels throughout Europe, it was collected from the hotel booking website [booking](www.booking.com). It has 17 features, and some very useful are the average score, hotel name, geographical latitude,nationality of the  geographical longitude, days since the review, negative word counts, and positive word counts.\n",
    "\n",
    "Each single observation contains one customer review with all the features. Despite the data being clean and with no missing values,we need to process the review text such that we have a quantifiable metric.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hotel = pd.read_csv(\"/content/drive/Shareddrives/COGS 118A - Final Project/Hotel_Reviews.csv\")\n",
    "hotel.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hotel.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hotel['Hotel_Address'].iloc[2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hotel['Tags'].nunique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tags_unique(lst) :\n",
    "  lst = lst.split(',')\n",
    "\n",
    "  return lst\n",
    "\n",
    "dhotel = hotel['Tags']\n",
    "final = []\n",
    "for row in dhotel:\n",
    "  row = row.replace('[', '')\n",
    "  row = row.replace(']', '')\n",
    "  row = row.replace(\"'\", '')\n",
    "  row = row.split(',')\n",
    "  for i in range(len(row)):\n",
    "    final.append(row[i])\n",
    "final = set(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allwords=[]\n",
    "words=list(final)\n",
    "\n",
    "for a in range(len(words)):\n",
    "  str=words[a]\n",
    "  sentence=set(str.split(\" \")) \n",
    "  for element in sentence:\n",
    "    # add each element to the set\n",
    "    allwords.append(element)\n",
    "\n",
    "word_df=pd.DataFrame(allwords)\n",
    "\n",
    "print(word_df.nunique()) \n",
    "\n",
    "print(word_df.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_df.value_counts()[:20].plot(kind='barh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lat/Long Country locator#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hotel['Hotel_Address'] = hotel['Hotel_Address'].str.strip()\n",
    "hotel['Country'] = np.asarray(hotel['Hotel_Address'].str.split(' '))\n",
    "hotel['Country'] = hotel['Country'].str[-1]\n",
    "hotel.loc[hotel.Country == 'Kingdom','Country'] = 'United Kingdom'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hotel['days_since_review'] = hotel['days_since_review'].str.split(' ').str[0].astype(int)\n",
    "hotel['Review_Date'] = pd.to_datetime(hotel['Review_Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hotel['Country'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hotel_countries = hotel.groupby(['Country']).agg({'Total_Number_of_Reviews': lambda x: sum(x), 'Reviewer_Score': lambda x: np.median(x), 'days_since_review': lambda x: np.mean(x) ,'Reviewer_Nationality': lambda x: list(set(x)), 'Hotel_Name': lambda x: len(list(set(x)))})\n",
    "hotel_countries = hotel_countries.rename(columns={'Hotel_Name':'Number_Hotels', 'Reviewer_Score':'Median_Reviewer_Score', 'days_since_review':'Means_Days_Review'})\n",
    "hotel_countries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Review_Date into date time object \n",
    "\n",
    "hotel['Review_Date']= pd.to_datetime(hotel['Review_Date']) \n",
    "# hotel['Review_Date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a column to one-hot encode whether there is a view or not\n",
    "# 1 --> there is a view\n",
    "# 0 --> there is no view mentioned in the tags\n",
    "\n",
    "view_count = 0\n",
    "view = []\n",
    "for i,tag in enumerate(dhotel): \n",
    "    #print (tag.dtype)\n",
    "    if tag.find('view') != -1:\n",
    "        view_count +=1\n",
    "        view.append(1)\n",
    "    elif tag.find('View') != -1:\n",
    "        view_count+=1\n",
    "        view.append(1)\n",
    "    else:\n",
    "        view.append(0)\n",
    "\n",
    "print(\"The number of entries where a view is mentioned:\", view_count)\n",
    "\n",
    "# Add the one hot encoded column for View to the hotel dataframe\n",
    "hotel['View'] = view\n",
    "\n",
    "# Entries that have a view\n",
    "hotel.loc[hotel['View'] == 1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regular vs Premium Room"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hotel = hotel.assign(regular = np.zeros(hotel.shape[0]), deluxe = np.zeros(hotel.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_tags(row):\n",
    "    row = row.replace('[', '')\n",
    "    row = row.replace(']', '')\n",
    "    row = row.replace(\"'\", '')\n",
    "    row = row[1:-1]\n",
    "    row = row.split(',')\n",
    "    \n",
    "    return row\n",
    "\n",
    "hotel['Tags'] = hotel['Tags'].apply(clean_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deluxe(row):\n",
    "    for deluxe in ['Deluxe', 'Premium', 'Superior', 'Prestige', 'Executive', 'Junior', \n",
    "                   'Penthouse', 'Privilege', 'Luxury', 'Sky', 'VIP', 'Fabulous', \n",
    "                   'Presidential', 'Grand']:\n",
    "        if row['Tags'].__contains__(deluxe):\n",
    "            return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_deluxe = []\n",
    "for i in range(hotel.shape[0]):\n",
    "    row = hotel.loc[i]['Tags']\n",
    "    deluxe = False\n",
    "    for tag in row:\n",
    "        for deluxe in ['Deluxe', 'Premium', 'Superior', \n",
    "                       'Prestige', 'Executive', 'Junior', \n",
    "                       'Penthouse', 'Privilege', 'Luxury',\n",
    "                      'Sky', 'VIP', 'Fabulous', 'Presidential', \n",
    "                      'Grand']:\n",
    "            if deluxe in row:\n",
    "                deluxe = True\n",
    "                break\n",
    "        if deluxe == True:\n",
    "            break\n",
    "    is_deluxe.append(deluxe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(is_deluxe)):\n",
    "    if is_deluxe[i]:\n",
    "        hotel.at[i,'deluxe'] = 1\n",
    "    else:\n",
    "        hotel.at[i,'regular'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a column to keep track of the size of the party from the tags column \n",
    "\n",
    "hotel['Formatted_Tags'] = dhotel \n",
    "#hotel.loc[hotel['Formatted_Tags'] == 'Adults'] \n",
    "\n",
    "adults = []\n",
    "children = []\n",
    "total_guests = []\n",
    "for i,tag in enumerate(dhotel):\n",
    "    num_adults = 0\n",
    "    num_children = 0\n",
    "    num_guests = 0\n",
    "    if tag.find('Adult') != -1:\n",
    "        ind = tag.index('Adult')\n",
    "        num_adults = tag[ind-2 : ind-1]\n",
    "    if tag.find('Adults') != -1:\n",
    "        ind = tag.index('Adults')\n",
    "        num_adults = tag[ind-2 : ind-1]\n",
    "    if tag.find('Child') != -1:\n",
    "        ind = tag.index('Child')\n",
    "        num_children = tag[ind-2 : ind-1]\n",
    "    if tag.find('Children') != -1:\n",
    "        ind = tag.index('Children')\n",
    "        num_children = tag[ind-2 : ind-1]\n",
    "    num_guests = int(num_adults) + int(num_children)\n",
    "    adults.append(num_adults)\n",
    "    children.append(num_children)\n",
    "    total_guests.append(num_guests) \n",
    "    \n",
    "hotel['Adults'] = adults\n",
    "hotel['Children'] = children\n",
    "hotel['Total_Guests'] = total_guests\n",
    "    \n",
    "print(\"The number of entries that note 1   or more guests:\", hotel.loc[hotel['Total_Guests'] >= 1].size)\n",
    "\n",
    "hotel.loc[hotel['Total_Guests'] >= 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tag Data and Hotel Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags=hotel[\"Tags\"]\n",
    "room_size_list=tags  \n",
    " \n",
    "tag_size=[]\n",
    "problematic_locations=[] # this is so i can look at the type of information tags are if they only have two\n",
    "three=[]\n",
    "four=[] \n",
    "five=[]\n",
    "six=[]\n",
    "problematic_tags=[]\n",
    "for num in range(len(room_size_list)):\n",
    "  a=room_size_list[num]\n",
    "  tag_size.append(len(a))\n",
    "  if (len(a)<=2):\n",
    "    problematic_locations.append(num)\n",
    "    problematic_tags.append(a)\n",
    "  if(len(a)==6):\n",
    "    six.append(a) \n",
    "  if(len(a)==5):\n",
    "    five.append(a) \n",
    "  if(len(a)==4):\n",
    "    four.append(a) \n",
    "  if(len(a)==3):\n",
    "    three.append(a) \n",
    "\n",
    "\n",
    "print(tag_size.count(0))\n",
    "print(tag_size.count(1))\n",
    "print(tag_size.count(2)) \n",
    "print(tag_size.count(3)) \n",
    "print(tag_size.count(4)) \n",
    "print(tag_size.count(5)) \n",
    "print(tag_size.count(6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting room sizes \n",
    "bed_list=[]\n",
    "for num in range(len(room_size_list)):\n",
    "  temp_review=room_size_list[num]\n",
    "  #all tags do not have the same amount of information as others. Some only have one or two tags. (The code looking at the tags is above) Fortunately the order is mostly the same \n",
    "  #thus based on the number of tags, we can the \"room type\" category\n",
    "  \n",
    "  length_tag=len(temp_review)\n",
    "  if(length_tag==6): #tags with 6 allways follow the same pattern, with the fourth being the room tag\n",
    "    temp_string=temp_review[3]\n",
    "  elif(length_tag<=2):# all tags 2 or lower do not have the room type. There is code below that sets those with unknown rooms as 1 (for 1 bed)\n",
    "    temp_string=temp_review[0]\n",
    "  elif(length_tag==3): #though not all tags with 3 have the room, if it does, it is all located as the second value of the list \n",
    "    temp_string=temp_review[1]\n",
    "  else:#those with 4 or 5 tag have the the room type as the third (the difference between 4 or 5 tags is the addition of mobile reviews for the fifth one)\n",
    "    temp_string=temp_review[2]\n",
    "\n",
    "\n",
    "  #before counting how many beds there are ( a rough estimate of size other than number of people), we need to do some cleaning to help clear some of the uneeded info\n",
    "  temp_string=temp_string.lower()\n",
    "  if (\"children\" in temp_string): \n",
    "    ind = temp_string.index('children')\n",
    "    temp_string= temp_string.replace(temp_string[ind-2 : ind-1],\"\")\n",
    "  elif(\"child\" in temp_string ):  \n",
    "    ind = temp_string.index('child')\n",
    "    temp_string= temp_string.replace(temp_string[ind-2 : ind-1],\"\")\n",
    "\n",
    "  if (\"adults\" in temp_string):\n",
    "    ind = temp_string.index('adults')\n",
    "    temp_string= temp_string.replace(temp_string[ind-2 : ind-1],\"\") \n",
    "  elif(\"adult\" in temp_string):  \n",
    "    ind = temp_string.index('adult')\n",
    "    temp_string= temp_string.replace(temp_string[ind-2 : ind-1],\"\")\n",
    "\n",
    "  if(\"people\" in temp_string):\n",
    "    ind = temp_string.index('people')\n",
    "    temp_string= temp_string.replace(temp_string[ind-2 : ind-1],\"\")\n",
    "\n",
    "  number_of_beds=0 \n",
    "  #unfortunately, there is not one clear way to check how many beds there are based on a tag. Thus, we need to be able to extract some of the signifiers and use those to approximate the number of beds\n",
    " \n",
    "  # Lets start with dealing with the word \"and\". By splitting the string, we can make it so that a room with a queen and a single can be counted as two beds rather than one \n",
    "  if(\"and\" in temp_string):  \n",
    "    temp_string=temp_string.split(\"and\")\n",
    "  else: \n",
    "    temp_string=[temp_string]\n",
    "\n",
    "#unfortunately, the tags are less than standardized. Thus to count the number of beds, we need to have a hiearchy \n",
    "#from looking at the tags, numbers are used for two things: number of beds and people.\n",
    "  for phrase in temp_string:\n",
    "    if(phrase.isdigit()):\n",
    "      num_list=[int(b) for b in phrase.split()]\n",
    "      number_of_beds+= max(num_list)\n",
    "    else:\n",
    "      if (\"quintuple\" in phrase): \n",
    "        number_of_beds+=5\n",
    "      elif(\"quadruple\" in phrase): \n",
    "        number_of_beds+=4\n",
    "      elif(\"triple\" in phrase):\n",
    "        number_of_beds+=3 \n",
    "      elif(\"twin\" in phrase):\n",
    "        number_of_beds+=2\n",
    "      elif(\"double\" in phrase): \n",
    "        number_of_beds+=2\n",
    "      elif(number_of_beds==0 and \"family\" in phrase):\n",
    "        number_of_beds=2\n",
    "      elif(\"single\" in phrase):\n",
    "        number_of_beds+=1\n",
    "      else: \n",
    "        number_of_beds+=1\n",
    "\n",
    "    if(\"extra\" in phrase): \n",
    "      number_of_beds+=1  \n",
    "    if(\"sofa\" in phrase):\n",
    "      if(\"with double sofa\" in phrase): \n",
    "        number_of_beds+=2\n",
    "      if(\"double sofa\" in phrase == False):\n",
    "        if(\"extra sofa\" in phrase == False):\n",
    "            number_of_beds+=1 \n",
    "\n",
    "  bed_list.append(number_of_beds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hotel[\"bed_list\"]=bed_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting the average score for each hotel\n",
    "avgscore_count = hotel.groupby([\"Average_Score\"]).agg(\n",
    "    Count =pd.NamedAgg(column = \"Average_Score\",aggfunc=\"count\")\n",
    ")   \n",
    "avg = sns.lineplot(x= \"Average_Score\", y = \"Count\", data = avgscore_count)\n",
    "avg.set(xlabel = \"Average Score\")\n",
    "hotel.boxplot(column=['Average_Score'])\n",
    "avgm = hotel['Average_Score'].mean()\n",
    "avgmed = hotel[\"Average_Score\"].median()\n",
    "print(\"Median and Median of Average Scores\")\n",
    "print(avgm)\n",
    "print(avgmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#countplots for positive and negative word counts in reviews\n",
    "pos_word_count = hotel.groupby([\"Review_Total_Positive_Word_Counts\"]).agg(\n",
    "    Count =pd.NamedAgg(column = \"Review_Total_Positive_Word_Counts\",aggfunc=\"count\")\n",
    ")   \n",
    "pos =sns.lineplot(x= \"Review_Total_Positive_Word_Counts\", y = \"Count\", data = pos_word_count)\n",
    "pos.set(xlabel = \"Positive Word Counts in Reviews\")\n",
    "\n",
    "print(\"Mean and Median For Positive Word Counts\")\n",
    "pos_m = hotel['Review_Total_Positive_Word_Counts'].mean()\n",
    "pos_med = hotel[\"Review_Total_Positive_Word_Counts\"].median()\n",
    "print(pos_m)\n",
    "print(pos_med)\n",
    "\n",
    "neg_word_count = hotel.groupby([\"Review_Total_Negative_Word_Counts\"]).agg(\n",
    "    Count =pd.NamedAgg(column = \"Review_Total_Negative_Word_Counts\",aggfunc=\"count\")\n",
    ")   \n",
    "neg = sns.lineplot(x= \"Review_Total_Negative_Word_Counts\", y = \"Count\", data = neg_word_count)\n",
    "neg.set(xlabel = \"Negative Word Counts in Reviews\")\n",
    "\n",
    "print(\"Mean and Median For Negative Word Counts\")\n",
    "neg_m = hotel['Review_Total_Negative_Word_Counts'].mean()\n",
    "neg_med = hotel[\"Review_Total_Negative_Word_Counts\"].median()\n",
    "print(neg_m)\n",
    "print(neg_med)\n",
    "\n",
    "\n",
    "#note: there is a really big right tail on both graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#countplots for adults, children, and total guests\n",
    "sns.countplot( x = 'Adults', data = hotel)\n",
    "print(hotel['Adults'])\n",
    "hotel = hotel.astype({'Children':'int'})\n",
    "sns.countplot(x = 'Children', data = hotel)\n",
    "guests =sns.countplot(x=\"Total_Guests\", data=hotel[-(hotel.Total_Guests == 0)])\n",
    "guests.set(xlabel = \"Total # of Guests During Visit\")\n",
    "\n",
    "print(\"Mean and Median Adults:\")\n",
    "ad_m = hotel['Adults'].mean()\n",
    "ad_med = hotel[\"Adults\"].median()\n",
    "print(ad_m)\n",
    "print(ad_med)\n",
    "\n",
    "print(\"Mean and Median Children:\")\n",
    "ch_m = hotel['Children'].mean()\n",
    "ch_med = hotel[\"Children\"].median()\n",
    "print(ch_m)\n",
    "print(ch_med)\n",
    "\n",
    "#need to change so that the mean and median does not account for the 0 values\n",
    "print(\"Mean and Median of Total # of Guests\")\n",
    "totalg_m = hotel['Total_Guests'].mean()\n",
    "totalg_med = hotel[\"Total_Guests\"].median()\n",
    "print(totalg_m)\n",
    "print(totalg_med)\n",
    "#note: a huge number of 0s for each category - so can'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From our plots of the number of adult, children, and total guests, we can see that there are many 0 values for each category. As noted before, the total amount of reviews that list 1 or more guests is 248,630. Therefore, we can assume that the rest of the values had a 0 value mostly due to a lack of information. However, this also means that for the adult and chidren categories, we cannot make a firm conclusion on whether there were no adults or children, or whether the 0 value was due to missing information. On the other hand, we assume that there cannot be 0 total guests in a review since there must be at least one person to review the hotel. Therefore, we can get rid of the reviews that had a value of 0 when plotting the number of guests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#country countplot\n",
    "print(\"Most Common Country\")\n",
    "print(hotel['Country'].mode())\n",
    "country = sns.countplot(x = 'Country', data = hotel)\n",
    "country.set_xticklabels( ('Netherlands', 'UK', 'France',\"Spain\", \"Italy\", \"Austria\") )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#view countplot\n",
    "view = sns.countplot(x = \"View\", data = hotel)\n",
    "view.set_xticklabels( ('No View', 'View') )\n",
    "#note: a big ratio of no views:views"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be assumed that there a large amount of no views because there were some reviews that did not mention if there was a view or not. Therefore, we cannot conclude that all of the \"No Views\" reviews did not actually have a review, because there is a possibility that the view was simply not stated in the person's review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(hotel_countries.index,hotel_countries['Number_Hotels'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proposed Solution\n",
    "\n",
    "Our proposed solution to predicting a hotel’s average score and an individual’s score of a hotel will have multiple parts: Preprocessing, data cleaning, sentiment analysis of written reviews, determining the best classifier for predicting scores, and finally, training, testing, and evaluation. <br>\n",
    "\n",
    "To begin, here are the libraries we plan on using. <br>\n",
    "import numpy as np<br>\n",
    "import pandas as pd<br>\n",
    "from nltk.corpus import stopwords<br>\n",
    "from wordcloud import STOPWORDS<br>\n",
    "import matplotlib.pyplot as plt<br>\n",
    "import string<br>\n",
    "\n",
    "To preprocess and clean our data we have to remove any entries with missing values as well as remove those that correspond to reviewers who did not write out reviews and instead only gave numerical scores. Since we plan on using sentiment analysis to classify the written reviews, we need to remove the entries that did not provide any additional information aside from a score. We then need to remove any columns that correspond to features we do not need. <br>\n",
    "Thus, the variables we plan on using are: <br>\n",
    "the review date<br>\n",
    "the average hotel score<br>\n",
    "hotel name<br>\n",
    "reviewer nationality<br>\n",
    "negative review <br>\n",
    "positive review<br>\n",
    "the number of reviews the reviewer has given in the past<br>\n",
    "total number of valid reviews that the hotel has<br>\n",
    "tags the reviewer has given the hotel. <br>\n",
    "\n",
    "\n",
    "In order to perform sentiment analysis on the reviews we must perform some text cleaning. Namely, getting rid of stopwords, punctuation, and converting all letters to lowercase. We plan on performing a sentiment classification on the written reviews that will make the data quantitatively easier to put into our hotel rating prediction classifier. One way we can perform sentiment classification on the reviews is through using logistic regression to determine how positive or negative a review is. \n",
    "\n",
    "Next, we want to determine a classification model that would best predict the hotel ratings. The specific input we plan on using in this model are the nine variables listed above. Some potential models we could use include OLS and KNN. For instance, if we went with KNN we could use the ten closest neighbors and find the mean score of them.  We could also use a recurrent neural network (RNN) using Keras to perform sentiment analysis and classify the reviews.\n",
    "\n",
    "To split our data into train and test sets, we will use 80% for training and 20% for testing, choosing what entry goes into which set randomly. Once we train our model we will test it, run our evaluation metrics, and plot our results using Matplotlib. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Metrics\n",
    "\n",
    "For our evaluation metrics, we have chosen to use the precision and recall scores to evaluate how many of our positive reviews are actually positive and how many of our negative reviews are actually negative. This will allow us to determine how good our model is at distinguishing positive from negative and therefore measure the accuracy of our model. \n",
    "\n",
    "\n",
    "To determine the errors we will use a confusion matrix to display the summary of our evaluations and calculate the errors made in our classification model. Through our confusion matrix, we will determine the sensitivity and specificity of our model, and our goal is to have high specificity and high sensitivity. As we tweak our model, we will compare the confusion matrices and re-train our model according to the results. \n",
    "\n",
    "\n",
    "A confusion matrix has two columns and two rows, where the columns are the true positive and negative conditions and the rows are the predicted positive and negative conditions. We have provided an example of what our confusion matrix might look like below.\n",
    "\n",
    "![img1](images/ex_confusion_matrix)\n",
    "\n",
    "For a confusion matrix we want to reduce the amount of errors our model makes and maximize our precision and recall scores while running our model on our testing data.\n",
    "\n",
    "The precision score (true positive rate) is calculated at the amount of true positives divided by the total amount of positives (true positives and false positives). \n",
    "\n",
    "        Precision = true positives / (true positives + false positives)\n",
    "\n",
    "The recall score (true negative rate) is calculated as the amount of true negatives divided by the total amount of negatives (true negatives and false negatives). \n",
    "\n",
    "        Recall = true negatives / (true negatives + false negatives)\n",
    "\n",
    "The below table from Lecture 12 slides (subsequently taken from https://en.wikipedia.org/wiki/Precision_and_recall)[<sup>[4]</sup>] contains the mathematical representations from which the precision and recall are derived as well as contains other evaluation metrics which may prove useful as we begin to evaluate our model.\n",
    "\n",
    "![img2](images/wiki_prec_recall_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminary results\n",
    "\n",
    "NEW SECTION!\n",
    "\n",
    "Please show any preliminary results you have managed to obtain.\n",
    "\n",
    "Examples would include:\n",
    "- Analyzing the suitability of a dataset or alogrithm for prediction/solving your problem \n",
    "- Performing feature selection or hand-designing features from the raw data. Describe the features available/created and/or show the code for selection/creation\n",
    "- Showing the performance of a base model/hyper-parameter setting.  Solve the task with one \"default\" algorithm and characterize the performance level of that base model.\n",
    "- Learning curves or validation curves for a particular model\n",
    "- Tables/graphs showing the performance of different models/hyper-parameters\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ethics & Privacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before beginning this project, our team has acknowledged potential ethics and privacy concerns that may arise from our data and implementation. Primarily, it is important to note that the dataset we plan on using is legally obtained as it is data from Booking.com that has been made publicly available. We discovered this specific collection of data from Kaggle.com, posted by Jiashen Liu who curated the dataset and made it available to the public domain to copy and modify as we intend to do. \n",
    "It is also important to acknowledge the potential biases in the dataset. Most notably, each data entry includes the nationality of the user which is one of the many various features provided by the dataset that we can use to predict the user’s score of the hotel. We take this into consideration as it can result in a potential bias in our predictions. \n",
    "Our team has also taken into consideration the privacy of the responders and has assured that the privacy of all reviewers is upheld as there are no identifying personal features other than the reviewer’s nationality. However, though there may be personal information in specific written reviews, all information was freely given by the individual. Thus, the anonymity of individuals is maintained. One way we can address these ethical and privacy concerns is through using an ethics checklist that addresses important ethical considerations in data collection, modeling, and analysis. A useful tool we can use to add such a checklist to our project is the command line tool, Deon. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Team Expectations "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our team expectations strive to be in accordance with COGS 118A policies and guidelines. Each member has the responsibility to participate equally in all aspects of the project and communicate if any conflicts or difficulties arise. Meeting times will be planned in accordance with personal schedules and each member has a commitment to attend the meetings or make up any work if they are unable to attend. To keep things on a timely schedule each team member must be attentive to group conversations and keep in contact about any problems, ideas, or thoughts that could contribute to the project. In dividing any work among team members, each team member has the responsibility to contribute equally and finish their responsibilities at a timely manner. Additionally, each team member will be responsible for reviewing and communicating feedback as a whole before they are turned. If any conflicts arise, it is expected to be handled in a professional manner with consideration of all team members. Overall, it is expected that each team member will contribute equally and actively communicate to the rest of the team.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Timeline Proposal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "| Meeting Date  | Meeting Time| Completed Before Meeting  | Discuss at Meeting |\n",
    "|---|---|---|---|\n",
    "| 4/21  |  7 PM |  Individual assigned for project proposal and write on shared document  | Review and turn in project proposal |\n",
    "| 4/25 |  3 PM |  Consider general project information, possible questions, and variables | Discuss peer review assignment and divide parts | \n",
    "| 4/29  | 3PM | Finish individual peer review assignments  | General review of peer review assignment and turn in |\n",
    "| 5/2  | 3PM |Consider specifics about the data and think about ideas to discuss with group; background research| Discuss how to clean data; assign work to do individually |\n",
    "| 5/4 | 7 PM  | Continue assigned work for datasets, import and wrangle data | Discuss EDA methods; begin programming|\n",
    "| 5/6  | 3 PM  | Assigned parts for EDA| Discuss next steps and possible features, algorithms, and metrics; look at EDA analysis and discuss |\n",
    "| 5/9  |3 PM | Work on possible pilot results | Touch base with work and continuing pilot results  | \n",
    "|5/11|7 PM|Work on check point 1|Discuss individual work for checkpoint 1 and assign parts for peer review| \n",
    "|5/13|3 PM|Assigned coding for each member; work check point 1|Review all code written and make edits if needed, finalize and turn in check point 1| \n",
    "|5/16|3 PM|Work on coding and testing different possible models|Discuss models, finalize project solutions and assign programming; assign check point  peer review work| \n",
    "|5/20|7 PM|Finished assigned parts for peer reviews|Finalize and turn in checkpoint peer reviews| \n",
    "|5/27|3 PM|Refine coding and algorithms|Discuss final details and assign coding work to be done before next meeting| \n",
    "|6/1|7 PM|Work on assigned parts and be prepared to show teammates|Discuss collected work and divide work for end of project| \n",
    "|6/8|3 PM|Complete team eval survey separately|Overall review of final project, finalize, and turn in|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Footnotes\n",
    "<a name=\"lorenznote\"></a>1.[^](#lorenz): Lorenz, T. (9 Dec 2021) Birds Aren’t Real, or Are They? Inside a Gen Z Conspiracy Theory. *The New York Times*. https://www.nytimes.com/2021/12/09/technology/birds-arent-real-gen-z-misinformation.html<br> \n",
    "<a name=\"admonishnote\"></a>2.[^](#admonish): Also refs should be important to the background, not some randomly chosen vaguely related stuff. Include a web link if possible in refs as above.<br>\n",
    "<a name=\"sotanote\"></a>3.[^](#sota): Perhaps the current state of the art solution such as you see on [Papers with code](https://paperswithcode.com/sota). Or maybe not SOTA, but rather a standard textbook/Kaggle solution to this kind of problem\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
